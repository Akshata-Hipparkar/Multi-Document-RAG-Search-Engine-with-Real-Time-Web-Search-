# ğŸš€ GA02: Multi-Document Hybrid RAG Search Engine  
**Documents + Real-Time Web Intelligence**

---

## ğŸ“Œ Project Overview

**GA02** is a **Hybrid Retrieval-Augmented Generation (RAG) Search Engine** that enables intelligent question-answering across:

- ğŸ“„ **Multiple local documents** (PDFs, text files)
- ğŸŒ **Real-time web data** (via Tavily Search)

The system dynamically decides **where to retrieve information from** â€” documents, live web, or both â€” and generates **grounded answers with clear citations**, all through a clean **Streamlit-based chatbot UI**.

This project simulates **real-world enterprise AI copilots** used in research, knowledge intelligence, and internal search platforms.

---

## ğŸ¯ Objective

The primary goal of this project is to build a **medium-complexity hybrid RAG system** that:

- Creates a searchable knowledge base from multiple documents
- Uses **FAISS** for semantic vector search
- Integrates **Tavily** for real-time web queries
- Classifies queries into **Document / Web / Hybrid**
- Generates **citation-aware answers**
- Provides a user-friendly **Streamlit UI**

---

## ğŸ§  Key Capabilities

- ğŸ” **Multi-document semantic search**
- ğŸ§© **Hybrid RAG architecture**
- ğŸŒ **Live web search integration**
- ğŸ§  **LLM-based query routing**
- ğŸ“ **Source-grounded answers**
- ğŸ¨ **Modern, cinematic Streamlit UI**
- ğŸ§ª **Transparent evidence inspection**

---

## ğŸ› ï¸ Tech Stack (Strictly Followed)

| Component | Technology |
|--------|-----------|
| Programming Language | Python |
| LLM Orchestration | LangChain |
| Vector Database | FAISS |
| Embeddings | HuggingFace (MiniLM) |
| LLM | Groq (LLaMA 3.1) |
| Web Search | Tavily Search |
| Frontend | Streamlit |
| Environment | dotenv |

---

## ğŸ“‚ Data Sources

### Local Knowledge Base
- PDF documents
- Text files
- Wikipedia pages (via LangChain loaders)

### Real-Time Knowledge
- Tavily Web Search:
  - Current events
  - Recent research
  - Live statistics
  - News & updates

---

## ğŸ”¹ Core Pipeline Breakdown

### 1ï¸âƒ£ Document Ingestion
- Upload PDFs and text files via Streamlit
- Load documents using LangChain loaders
- Normalize metadata for traceability

### 2ï¸âƒ£ Text Chunking
- Recursive character chunking
- Overlapping windows for better context
- Metadata preserved per chunk

### 3ï¸âƒ£ Vector Indexing
- Generate embeddings using HuggingFace MiniLM
- Store vectors in FAISS
- Perform semantic similarity search

### 4ï¸âƒ£ Query Classification
LLM-based routing categorizes queries as:
- **DOC** â†’ Internal documents only
- **WEB** â†’ Real-time web search
- **HYBRID** â†’ Documents + Web

### 5ï¸âƒ£ Web Search (Tavily)
- Executes live search queries
- Retrieves titles, snippets, and URLs
- Treated as **temporary context**, not indexed

### 6ï¸âƒ£ Context Assembly
- Combines document chunks + web snippets
- Applies size limits
- Tags sources clearly

### 7ï¸âƒ£ Answer Generation
- LLM generates grounded responses
- Explicit citations:
  - `[Doc: filename]`
  - `[Web: URL]`

---

## ğŸ’¬ Streamlit UI Features

### Sidebar
- ğŸ“‚ Document uploader
- ğŸ” Toggle Tavily web search ON/OFF
- ğŸ“Š Indexed file overview

### Main Chat Interface
- Natural language query input
- Hybrid response generation
- Real-time feedback

### Evidence Tabs
- âœ¨ Grounded Answer
- ğŸ“„ Document Evidence
- ğŸŒ Web Evidence

---

## ğŸ§ª Evaluation Scenarios

| Scenario | Result |
|-------|--------|
| Static document queries | Accurate & grounded |
| Current events | Live web results used |
| Comparative queries | Hybrid reasoning |
| Source transparency | Clear & traceable |

---

## ğŸ“ˆ Strengths

- Real-world hybrid RAG design
- Clean separation of document vs web knowledge
- Transparent citations
- Modular LangChain pipeline
- Strong UI/UX clarity

---

## âš ï¸ Limitations

- FAISS index is rebuilt per session
- No long-term persistence
- Query classification relies on LLM judgment
- No multi-user state handling

---

## ğŸš€ Future Enhancements

- Persistent vector storage
- Feedback-based retrieval scoring
- Multi-modal document support
- Advanced ranking & re-ranking
- User authentication & history

---

## ğŸ“š Key Learnings

âœ” Multi-document RAG architecture  
âœ” Hybrid retrieval design  
âœ” Real-time web integration  
âœ” Citation-aware generation  
âœ” LangChain + Streamlit production patterns  

---

## ğŸ Conclusion

This project demonstrates a **production-style Hybrid RAG syst**
